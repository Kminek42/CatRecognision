{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "class CatsDataset(Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        if train:\n",
    "            temp_dataset = load_dataset(\"cifar10\")['train']\n",
    "        else:\n",
    "            temp_dataset = load_dataset(\"cifar10\")['test']\n",
    "        \n",
    "        self.dataset = []\n",
    "        for i in range(len(temp_dataset)):\n",
    "            if temp_dataset[i]['label'] == 3:\n",
    "                img = torchvision.transforms.PILToTensor()(temp_dataset[i]['img']).expand((3, -1, -1)) / 255.0\n",
    "                self.dataset.append([img, torch.tensor([0])])\n",
    "\n",
    "            elif torch.rand((1, )) < 1/9:\n",
    "                img = torchvision.transforms.PILToTensor()(temp_dataset[i]['img']).expand((3, -1, -1)) / 255.0\n",
    "                self.dataset.append([img, torch.tensor([1])])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.dataset[idx]\n",
    "        image = torchvision.transforms.RandomHorizontalFlip()(image)\n",
    "        image = torchvision.transforms.RandomResizedCrop((32, 32), scale=(4/5, 5/4), ratio=(4/5, 5/4))(image)\n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9947"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = CatsDataset(train=True)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "dev = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    dev = torch.device(\"mps\")\n",
    "\n",
    "print(f\"Using device: {dev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, 3),\n",
    "    nn.MaxPool2d((3, 3)),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(64, 64, 3),\n",
    "    nn.MaxPool2d((3, 3)),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(256, 64),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(64, 2)\n",
    ").to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.2303597243168415\n",
      "Epoch 2 Loss: 0.2216855757511579\n",
      "Epoch 3 Loss: 0.22574728612716383\n",
      "Epoch 4 Loss: 0.21387231579193702\n",
      "Epoch 5 Loss: 0.2225229140275564\n",
      "Epoch 6 Loss: 0.2211446838501172\n",
      "Epoch 7 Loss: 0.21931532407418275\n",
      "Epoch 8 Loss: 0.22609552511802086\n",
      "Epoch 9 Loss: 0.22340567983113802\n",
      "Epoch 10 Loss: 0.22543280476178879\n",
      "Epoch 11 Loss: 0.2320138460550553\n",
      "Epoch 12 Loss: 0.23016405143798926\n",
      "Epoch 13 Loss: 0.2272138584118623\n",
      "Epoch 14 Loss: 0.22688598892627618\n",
      "Epoch 15 Loss: 0.21831772457330656\n",
      "Epoch 16 Loss: 0.22534549121673292\n",
      "Epoch 17 Loss: 0.2202605929894325\n",
      "Epoch 18 Loss: 0.22407832397864416\n",
      "Epoch 19 Loss: 0.22122520361191186\n",
      "Epoch 20 Loss: 0.22534858645536962\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    s = 0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(dev)\n",
    "        labels = labels.to(dev)\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "        labels = labels.view(-1)\n",
    "        # Compute the loss and its gradients\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        s += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} Loss: {s/len(train_dataloader)}\")\n",
    "\n",
    "torch.save(model.to(dev).state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CatsDataset(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7975, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "good = 0\n",
    "a = 0\n",
    "for i, data in enumerate(test_dataloader):\n",
    "    # Every data instance is an input + label pair\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.to(dev)\n",
    "    labels = labels.to(dev)\n",
    "    outputs = model(inputs)\n",
    "    labels = labels.view(-1)\n",
    "    \n",
    "    for i in range(len(outputs)):\n",
    "        good += torch.argmax(outputs[i]) == labels[i]\n",
    "        a += 1\n",
    "\n",
    "print(good / a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
